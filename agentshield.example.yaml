# AgentShield Configuration Example
# Copy to pyagentshield.yaml and modify as needed
# Or set AGENTSHIELD_CONFIG_PATH environment variable

# =============================================================================
# Embedding Configuration
# =============================================================================
embeddings:
  # Provider: "local" (sentence-transformers), "openai", or "mlx" (Apple Silicon)
  provider: local

  # Local model (sentence-transformers or finetuned)
  # Options: all-MiniLM-L6-v2 (fast), all-mpnet-base-v2 (accurate)
  # For finetuned: your-username/agentshield-embeddings-zedd
  model: all-MiniLM-L6-v2

  # OpenAI model (if provider: openai)
  openai_model: text-embedding-3-small

  # OpenAI-compatible endpoint settings (for provider: openai)
  # Supports OpenAI-compatible backends (OpenRouter/Together/Ollama/vLLM/etc.)
  api_key: null
  base_url: null
  default_headers: null

  # Optional explicit embedding size for unknown OpenAI-compatible models
  # If null, dimensions are resolved from known mappings/cache/first response.
  dimensions: null

  # MLX settings (if provider: mlx, for Apple Silicon Macs)
  mlx_cache_dir: null  # Default: ~/.agentshield/mlx_models
  mlx_convert_from_hf: true  # Auto-convert from HuggingFace

# =============================================================================
# Text Cleaning Configuration
# =============================================================================
cleaning:
  # Method: "heuristic", "llm", "finetuned", or "hybrid"
  method: heuristic

  # LLM cleaner (when method: llm)
  llm_model: gpt-3.5-turbo

  # OpenAI-compatible endpoint settings for LLM cleaning (method: llm or hybrid with llm)
  api_key: null
  base_url: null
  default_headers: null

  # Finetuned cleaner settings (when method: finetuned)
  finetuned:
    # HuggingFace Hub model ID
    model_id: null  # e.g., "pyagentshield/cleaner-phi2-lora"

    # Or local path (takes precedence over model_id)
    model_path: null  # e.g., "/path/to/model"

    # Base model for LoRA
    base_model: microsoft/phi-2

    # Whether to load as LoRA adapter
    use_lora: true

    # Device: "auto", "cuda", "cpu", "mps"
    device: auto

    # Quantization (for memory efficiency)
    load_in_4bit: true
    load_in_8bit: false

    # Generation settings
    max_new_tokens: 256
    temperature: 0.1

  # Hybrid cleaner settings (when method: hybrid)
  hybrid:
    # Methods to combine (in order)
    methods:
      - heuristic
      - finetuned

    # Mode: sequential, fallback, parallel_vote, best_drift, least_drift
    mode: sequential

    # For parallel_vote mode
    vote_threshold: 0.5

    # Optional weights per method
    weights: null

# =============================================================================
# ZEDD Detection Configuration
# =============================================================================
zedd:
  # Detection threshold
  # null = auto-resolve/calibrate based on pipeline fingerprint
  # 0.0-1.0 = explicit threshold
  threshold: null

# =============================================================================
# Behavior Configuration
# =============================================================================
behavior:
  # Action when injection detected:
  # - block: raise PromptInjectionDetected exception
  # - warn: log warning, continue processing
  # - flag: add metadata to results
  # - filter: remove suspicious content
  on_detect: flag

  # Minimum confidence to trigger action (0.0-1.0)
  confidence_threshold: 0.5

# =============================================================================
# Performance Configuration
# =============================================================================
performance:
  # Batch size for embedding/cleaning operations
  batch_size: 32

  # Cache embeddings for repeated texts
  cache_embeddings: true

  # Cache directory for thresholds and models
  cache_dir: null  # Default: ~/.agentshield

# =============================================================================
# Logging Configuration
# =============================================================================
logging:
  # Level: DEBUG, INFO, WARNING, ERROR
  level: INFO

  # Format: "text" or "json"
  format: text

# =============================================================================
# Telemetry Configuration (AgentShield Cloud)
# =============================================================================
telemetry:
  # Enable/disable telemetry (default: true, but requires api_key to send)
  enabled: true

  # API key from AgentShield Cloud (required to activate telemetry)
  # Also settable via AGENTSHIELD_TELEMETRY__API_KEY env var
  api_key: null

  # Cloud endpoint
  endpoint: https://api.agentshield.dev/v1/telemetry

  # Project and environment labels (appear in dashboard)
  project: null       # e.g., "my-rag-app"
  environment: null   # e.g., "production", "staging"

  # Batching settings
  flush_interval: 30  # seconds between flushes
  batch_size: 50      # events per batch
