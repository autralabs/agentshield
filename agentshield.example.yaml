# AgentShield Configuration Example
# Copy to pyagentshield.yaml and modify as needed
# Or set AGENTSHIELD_CONFIG_PATH environment variable

# =============================================================================
# Embedding Configuration
# =============================================================================
embeddings:
  # Provider: "local" (sentence-transformers), "openai", or "mlx" (Apple Silicon)
  provider: local

  # Local model (sentence-transformers or finetuned)
  # Options: all-MiniLM-L6-v2 (fast), all-mpnet-base-v2 (accurate)
  # For finetuned: your-username/agentshield-embeddings-zedd
  model: all-MiniLM-L6-v2

  # OpenAI model (if provider: openai)
  openai_model: text-embedding-3-small

  # MLX settings (if provider: mlx, for Apple Silicon Macs)
  mlx_cache_dir: null  # Default: ~/.agentshield/mlx_models
  mlx_convert_from_hf: true  # Auto-convert from HuggingFace

# =============================================================================
# Text Cleaning Configuration
# =============================================================================
cleaning:
  # Method: "heuristic", "llm", "finetuned", or "hybrid"
  method: heuristic

  # LLM cleaner (when method: llm)
  llm_model: gpt-3.5-turbo

  # Finetuned cleaner settings (when method: finetuned)
  finetuned:
    # HuggingFace Hub model ID
    model_id: null  # e.g., "pyagentshield/cleaner-phi2-lora"

    # Or local path (takes precedence over model_id)
    model_path: null  # e.g., "/path/to/model"

    # Base model for LoRA
    base_model: microsoft/phi-2

    # Whether to load as LoRA adapter
    use_lora: true

    # Device: "auto", "cuda", "cpu", "mps"
    device: auto

    # Quantization (for memory efficiency)
    load_in_4bit: true
    load_in_8bit: false

    # Generation settings
    max_new_tokens: 256
    temperature: 0.1

  # Hybrid cleaner settings (when method: hybrid)
  hybrid:
    # Methods to combine (in order)
    methods:
      - heuristic
      - finetuned

    # Mode: sequential, fallback, parallel_vote, best_drift, least_drift
    mode: sequential

    # For parallel_vote mode
    vote_threshold: 0.5

    # Optional weights per method
    weights: null

# =============================================================================
# ZEDD Detection Configuration
# =============================================================================
zedd:
  # Detection threshold
  # null = auto-calibrate based on embedding model
  # 0.0-1.0 = explicit threshold
  threshold: null

# =============================================================================
# Behavior Configuration
# =============================================================================
behavior:
  # Action when injection detected:
  # - block: raise PromptInjectionDetected exception
  # - warn: log warning, continue processing
  # - flag: add metadata to results
  # - filter: remove suspicious content
  on_detect: flag

  # Minimum confidence to trigger action (0.0-1.0)
  confidence_threshold: 0.5

# =============================================================================
# Performance Configuration
# =============================================================================
performance:
  # Batch size for embedding/cleaning operations
  batch_size: 32

  # Cache embeddings for repeated texts
  cache_embeddings: true

  # Cache directory for thresholds and models
  cache_dir: null  # Default: ~/.agentshield

# =============================================================================
# Logging Configuration
# =============================================================================
logging:
  # Level: DEBUG, INFO, WARNING, ERROR
  level: INFO

  # Format: "text" or "json"
  format: text
